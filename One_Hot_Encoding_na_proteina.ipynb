{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One Hot Encoding na proteina.ipynb",
      "provenance": [],
      "mount_file_id": "1iMDn3fy0P2NVljWfh5VzyZ2_9XibDcmQ",
      "authorship_tag": "ABX9TyMyn+7EvBS+vyOH4btpih2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianIto/ML_DEN_RNA/blob/main/One_Hot_Encoding_na_proteina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgjIxL5K6sFB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ns1 = pd.read_csv('E_protein.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6aBWC6c9Z9T"
      },
      "source": [
        "#Transforma String do vetor do CSV em vetor.\n",
        "sequences = ns1[\"sequences\"].str.replace(\"[\", \"\")\n",
        "sequences = sequences.str.replace(\"]\", \"\")\n",
        "sequences = sequences.str.replace(\"'\", \"\")\n",
        "sequences = np.array(sequences.str.split(\", \"))\n",
        "ns1.sequences = sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yIhjm-1-B1h"
      },
      "source": [
        "#Severa == 1 e Classica == 0\n",
        "ns1[\"Label\"] = (ns1[\"outcome\"] == \"Severa\").astype(int)\n",
        "\n",
        "train_labels = np.array(ns1[\"Label\"])\n",
        "train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsHJAqfO_8j2"
      },
      "source": [
        "train_data = np.array(ns1[\"sequences\"])\n",
        "data_dict = {}\n",
        "\n",
        "#Cria Dicionário de Frequência\n",
        "for i, sequence in enumerate(train_data):\n",
        "  for j, codon in enumerate(sequence):\n",
        "    if (codon in data_dict):\n",
        "      data_dict[codon] += 1\n",
        "    else:\n",
        "      data_dict[codon] = 1\n",
        "\n",
        "#Cria Dicionário de Ranking de Aparição\n",
        "def getMaior(dict):\n",
        "  max, maxKey = -1, ''\n",
        "  for key in dict:\n",
        "    if (max < dict[key]):\n",
        "      max = dict[key]\n",
        "      maxKey = key\n",
        "  return max, maxKey\n",
        "  \n",
        "size = len(data_dict.keys())\n",
        "\n",
        "data_dict_copy = data_dict.copy()\n",
        "dict_final = {}\n",
        "\n",
        "for i in range(0, size):\n",
        "  max, maxKey = getMaior(data_dict_copy)\n",
        "  del data_dict_copy[maxKey]\n",
        "  dict_final[maxKey] = i + 1\n",
        "\n",
        "dict_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MlfHjAyDGtc"
      },
      "source": [
        "for i in range(0, ns1[\"sequences\"].shape[0]):\n",
        "  for j in range(0, len(ns1[\"sequences\"].loc[i])):\n",
        "    ns1[\"sequences\"].loc[i][j] = dict_final[ns1[\"sequences\"].loc[i][j]]\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqiH57CMP8Vk"
      },
      "source": [
        "ns1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BafdpjGRSGYl",
        "outputId": "01faddf4-f4a4-4da6-f4d6-6402ff124a86"
      },
      "source": [
        "arr = np.array(ns1.sequences)\n",
        "\n",
        "matriz = []\n",
        "for i, lista in enumerate(arr):\n",
        "  matriz_dispersao = np.zeros(71)\n",
        "  for j, elem in enumerate(lista):\n",
        "    matriz_dispersao[elem] += 1\n",
        "  matriz.append(matriz_dispersao.astype(int))\n",
        "\n",
        "train_data = np.array(matriz)\n",
        "ns1[\"matriz_disp\"] = matriz\n",
        "ns1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5ce3ec1afca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmatriz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlista\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmatriz_dispersao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m71\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wABYUs1lfbIQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "train_data = ns1[\"sequences\"]\n",
        "\n",
        "train_data.shape\n",
        "#tf.constant(train_data)\n",
        "train_data\n",
        "\n",
        "series = ns1[\"sequences\"].copy()\n",
        "slist = series.to_list()\n",
        "train_data = np.array(slist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiPHVd45bR29"
      },
      "source": [
        "arr = np.array(ns1[\"matriz_disp\"].to_list())\n",
        "\n",
        "totalCodons = arr.shape[1]\n",
        "totalSequences = arr.shape[0]\n",
        "\n",
        "x = np.zeros(totalSequences);\n",
        "y = np.zeros(totalSequences);\n",
        "\n",
        "for index, sequence in enumerate(arr):\n",
        "  if (index + 1 < totalSequences):\n",
        "    differenceMatrix = np.zeros(totalSequences)\n",
        "    counter = 0\n",
        "    for i, codon in enumerate(sequence):\n",
        "      if (i + 1  < totalCodons):\n",
        "        if (codon != arr[index + 1][i + 1]):\n",
        "          differenceMatrix[i] += 1\n",
        "          counter += 1\n",
        "    print(\"Posição: \" + str(index) + \", Taxa de Igualdade: \" + str(100 - (counter / totalSequences)))\n",
        "    x[index] = index;\n",
        "    y[index] = 100 - (counter / totalSequences)\n",
        "  \n",
        "plt.scatter(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpvxaSuzgLAE"
      },
      "source": [
        "from keras import models, Model\n",
        "from keras import layers \n",
        "\n",
        "def build_model():\n",
        "    inputs = layers.Input(shape=(None, 71)) # placeholder\n",
        "    x = layers.Dense(128, activation='relu')(inputs)\n",
        "    out = layers.Dense(1, activation='softmax')( x )\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[out], name=\"mnits_model\")\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    return model\n",
        "  \n",
        "modelito = build_model()\n",
        "\n",
        "history = modelito.fit(train_data[:100], train_labels[:100], epochs=20, batch_size=512, \n",
        "                       validation_data=(train_data[100:157], train_labels[100:157]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFn5PzI9q1qt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}